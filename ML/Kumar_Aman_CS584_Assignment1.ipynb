{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "228cf0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "a2d4ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid function to determine the target variable values\n",
    "\n",
    "#this function. will return values in between 0 and 1\n",
    "def sigmoid(z):\n",
    "    z_clip = np.clip(z, -1000,1000)\n",
    "    \n",
    "    #this will return values between 0 and 1\n",
    "    g = 1/(1 + np.exp(-z_clip))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "5d1b63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute loss of the problem statement \n",
    "def compute_loss(X, y, c, lambda_):\n",
    "    \n",
    "    # z =  m*x + c\n",
    "    z = np.dot(X, c)  \n",
    "    \n",
    "    \n",
    "    # log loss as per the formula given in the problem\n",
    "    log_loss = np.sum(y * z - np.log(1 + np.exp(z)))\n",
    "    \n",
    "    \n",
    "    # regularization added to all terms\n",
    "    reg = lambda_ * np.sum(c**2)\n",
    "    \n",
    "    #net loss \n",
    "    net_loss = -log_loss + reg\n",
    "    \n",
    "    return net_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "475edd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing gradient \n",
    "def compute_gradient(X, y, c, lambda_):\n",
    "    # z = mx + c\n",
    "    z = np.dot(X,c)\n",
    "    \n",
    "    #predicted values of y calculated by the sigmoid function\n",
    "    y_pred = sigmoid(z)\n",
    "    \n",
    "    #calculate the gradient of the function\n",
    "    gradient = np.dot(X.T, (y_pred - y)) + 2 * lambda_ * c\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "8b42b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute graient descent of the model and updating the coefficients \n",
    "def gradient_descent(X, y, initial_coeff, alpha, iters, lambda_):\n",
    "    \n",
    "    #copying coeffs with initial coefficients values\n",
    "    coeff = initial_coeff.copy()\n",
    "    \n",
    "    #initialize an empty array for old losses\n",
    "    old_losses = []\n",
    "    \n",
    "    #consider optimal loss to be negative infinity at the beginning\n",
    "    opt_loss = np.inf\n",
    "    \n",
    "    #optimized coefficients\n",
    "    opt_coeff = initial_coeff.copy()\n",
    "    \n",
    "    #update coefficients after every iteration \n",
    "    for i in range(iters):\n",
    "        \n",
    "        #computing loss at every iteration\n",
    "        loss = compute_loss(X, y, coeff, lambda_)\n",
    "        \n",
    "        #compute gradient at every iteration\n",
    "        gradient = compute_gradient(X, y, coeff, lambda_)\n",
    "        \n",
    "        #coefficients are updated after every iteration\n",
    "        coeff = coeff - alpha * gradient  \n",
    "        \n",
    "        if loss < opt_loss:\n",
    "            opt_loss = loss\n",
    "            opt_coeff = coeff.copy()\n",
    "            \n",
    "        old_losses.append(loss)\n",
    "        \n",
    "    return opt_coeff, old_losses, opt_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "94044137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute output either 0 or 1\n",
    "def predict_output(X, coeff):\n",
    "    \n",
    "    z = np.dot(X, coeff)\n",
    "    \n",
    "    #predict the output using sigmoid function\n",
    "    y_pred = sigmoid(z)\n",
    "    \n",
    "    #taking threshold/boundary value 0.5 \n",
    "    boundary = 0.5\n",
    "    \n",
    "    #output can be either 0 or 1 based on the boundary/throshold value\n",
    "    # output = 1; if y_pred >= 0.5\n",
    "    # output = 0; if y_pred < 0.5\n",
    "    output = (np.array(y_pred) >= boundary).astype(np.int64)\n",
    "    \n",
    "    #print(output) for testing purpose only\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "55df1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the accuracy of the model based on predicted y value and actual y value\n",
    "def calculate_accuracy(y_pred, y_actual):\n",
    "    \n",
    "    #calculating accuracy by comparing the actual values and the predicted values\n",
    "    #based on that accuracy is calculated\n",
    "    accuracy = np.mean(y_pred == y_actual)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "e3e7ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data12.csv')\n",
    "\n",
    "# Prepare the data\n",
    "X_train = data.iloc[:, :-1].values\n",
    "y_train = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "# Initializing the coefficients\n",
    "initial_coeff = np.zeros(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "27f3d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "#learning rate\n",
    "alpha = 2e-8\n",
    "\n",
    "#number of iterations\n",
    "iters = 300000\n",
    "\n",
    "#lambda value\n",
    "lambda_ = 0.5\n",
    "\n",
    "# Run gradient descent\n",
    "coeffs, _ ,loss= gradient_descent(X_train, y_train, initial_coeff, alpha, iters, lambda_)\n",
    "\n",
    "# predict the target variable values y\n",
    "y_predicted = predict_output(X_train, optimized_coeffs)\n",
    "\n",
    "#calculate the accuracy of the model based on the trainig values and the predicted values of target variable y\n",
    "accuracy = calculate_accuracy(y_train, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "4d14745e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (721023647.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[390], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Accuracy of the model is : {accuracy*100}%\"\\n)\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the model\n",
    "print(f\"Accuracy of the model is : {accuracy*100}%\"\\n)\n",
    "\n",
    "# Coefficients after runnig the radient descent\n",
    "print(f\"Coefficients (after gradient descent): {coeffs}\\n\")\n",
    "\n",
    "#optimized loss value is \n",
    "print(f\"Optimized loss: {loss}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecf31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
