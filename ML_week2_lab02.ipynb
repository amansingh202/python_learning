{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecb9889",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45ec374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To support multiple input features\\nBefore we have seen only one input feature\\nThis time we are going to take a look at multiple features\\nUsing numpy '"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To support multiple input features\n",
    "Before we have seen only one input feature\n",
    "This time we are going to take a look at multiple features\n",
    "Using numpy '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2731c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy and matplot library is going to be used \n",
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "#reduced display precion on numpy arrays\n",
    "np.set_printoptions(precision = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "589d6b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a problem statement table\n",
    "#here it has 4 features \n",
    "#size in sq ft, # bedrooms, # floors and age of home\n",
    "X_train = np.array([[2104,5,1,45], [1416,3,2,40], [852,2,1,35]])\n",
    "y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dee530a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is: (3, 4), type of X_train is: <class 'numpy.ndarray'> and \n",
      "X_train is : \n",
      "[[2104    5    1   45]\n",
      " [1416    3    2   40]\n",
      " [ 852    2    1   35]]\n"
     ]
    }
   ],
   "source": [
    "#here X is the vector containing input data samples\n",
    "#here y_train is the output values in our training data set\n",
    "\n",
    "#shape of X and y is\n",
    "print(f\"Shape of X is: {X_train.shape}, type of X_train is: {type(X_train)} and \\nX_train is : \\n{X_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1375a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape is: (4,) and its type is <class 'numpy.ndarray'>, and b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#parameters w1, w2, w3 and w4 based on the features\n",
    "#b is the scalar parameter\n",
    "b_init = 785.1811367994083\n",
    "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "\n",
    "print(f\"w_init shape is: {w_init.shape} and its type is {type(w_init)}, and b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b3cab695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction element by element when there is multiple features\n",
    "def predict_single_loop(x, w, b):\n",
    "    p = 0\n",
    "    \n",
    "    for i in range (x.shape[0]):\n",
    "        p_i = w[i]*x[i]\n",
    "        p = p + p_i\n",
    "    p = p + b\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ddb9ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X vector shape: (4,) and X vector value: [2104    5    1   45]\n",
      "Predicted output is: 459.9999976194083 and shape: ()\n"
     ]
    }
   ],
   "source": [
    "#Extract a single row and make prediction\n",
    "x_vec = X_train[0,:]\n",
    "print(f\"X vector shape: {x_vec.shape} and X vector value: {x_vec}\")\n",
    "\n",
    "#make a prediction\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"Predicted output is: {f_wb} and shape: {f_wb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c11a9",
   "metadata": {},
   "source": [
    "# Same can be done using dot product of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "48911031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot product of vectors consumes less time as compared to the row wise element multiplication'\n",
    "#using arrays\n",
    "\n",
    "def predict(x, w, b):\n",
    "    \n",
    "    p = np.dot(x, w) + b\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "265fb8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output is: 459.9999976194083 and shape is ()\n"
     ]
    }
   ],
   "source": [
    "#make the prediction for the same row\n",
    "f_wb = predict(x_vec, w_init, b_init)\n",
    "print(f\"Predicted output is: {f_wb} and shape is {f_wb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "89725bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute cost with multiple variables J(w,b) = (1/2m)*(f w,b(x(i)) - y(i))^2)\n",
    "\n",
    "def compute_cost(X, y, w, b):\n",
    "    cost = 0.0\n",
    "    #training data 'm'\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(X[i], w) + b\n",
    "        cost = cost + (f_wb_i - y[i])**2\n",
    "        \n",
    "    cost = cost / (2*m)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76076833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w: 1.5578904045996674e-12\n"
     ]
    }
   ],
   "source": [
    "#calculate cost \n",
    "\n",
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f\"Cost at optimal w: {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f5495863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating gradient descent with multiple variables\n",
    "\n",
    "#dJ(w,b)/db and dJ(w,b)/dw\n",
    "\n",
    "#number of training examples = m\n",
    "#number of features = n\n",
    "\n",
    "\n",
    "def compute_gradient(X, y, w, b):\n",
    "    \n",
    "    m,n = X.shape\n",
    "    \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        err = (np.dot(w, X[i]) + b) - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + (err * X[i,j])\n",
    "            \n",
    "        dj_db = dj_db + err\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "736357ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_dw at initial w and b is: [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]\n",
      "dj_db at initial w and b is: -1.6739251122999121e-06\n"
     ]
    }
   ],
   "source": [
    "#calculate and compute gradient \n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "\n",
    "print(f\"dj_dw at initial w and b is: {tmp_dj_dw}\")\n",
    "print(f\"dj_db at initial w and b is: {tmp_dj_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9cdc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent with multiple variables\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, aplha, num_iters):\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        dj_dw, dj_db = gradient_function(X, y, w, b)\n",
    "        \n",
    "        #update w and b parameters\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "        if i<1000000:\n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "            \n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i: 4d}: Cost {J_history[-1]: 8.2f}\")\n",
    "            \n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e3437498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost  2529.46\n",
      "Iteration  100: Cost   695.99\n",
      "Iteration  200: Cost   694.92\n",
      "Iteration  300: Cost   693.86\n",
      "Iteration  400: Cost   692.81\n",
      "Iteration  500: Cost   691.77\n",
      "Iteration  600: Cost   690.73\n",
      "Iteration  700: Cost   689.71\n",
      "Iteration  800: Cost   688.70\n",
      "Iteration  900: Cost   687.69\n",
      "b, w found by gradient descent: -0.00, [ 0.2   0.   -0.01 -0.07]\n",
      "Shape of m is: 3\n",
      "prediction: 426.19, target value: 460\n",
      "prediction: 286.17, target value: 232\n",
      "prediction: 171.47, target value: 178\n"
     ]
    }
   ],
   "source": [
    "#initialize parameters\n",
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0\n",
    "\n",
    "#some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "#run gradient descent\n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b, compute_cost, \n",
    "                                            compute_gradient,\n",
    "                                           alpha, iterations)\n",
    "\n",
    "print(f\"b, w found by gradient descent: {b_final:0.2f}, {w_final}\")\n",
    "\n",
    "m, _ = X_train.shape\n",
    "print(f\"Shape of m is: {m}\")\n",
    "\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd5695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
